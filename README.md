This repository contains the code for evaluating text simplification using the Flan-T5-base model. 
The main objective is to assess the performance of the model in zero-shot and few-shot learning scenarios 
for various text simplification tasks, focusing on audiences who need assistive technology for reading,
such as individuals with dyslexia or autism.

**Repository Structure**

- flan_T5_model_baseline_one_shot.py: Main script to run the text simplification experiments.

- evaluate.py: Script to evaluate the generated results using SARI and BERTScore.

- test_dataset.pkl: The test dataset used for evaluation.

- validation_dataset.pkl: The validation dataset used for creating few-shot examples.

- output_data_flan_t5_base_semantic_shots.json: Sample output JSON file generated by the model.

**Requirements** 
- Python 3.8 or above 
- PyTorch 
- Transformers library from Hugging Face 
- EASSE package for evaluation 
- CUDA-compatible GPU (optional for faster inference)

**Prepare data**

This rep serves for ASSET dataset, to prepare the validation and test data, you need to provide below` asset.valid.jsonl` 
and `asset.test.jsonl` to `data_load.py`. 

If you want to get the source of the data, please contact the author of the rep.

data_dir = Path("resources/data/asset/dataset")
validation_file = data_dir / "asset.valid.jsonl"
test_file = data_dir / "asset.test.jsonl"

**Usage**
Running the Text Simplification Experiment

To run the main text simplification experiment, execute:

`python flan_T5_model_baseline_one_shot.py`

This script will load the Flan-T5-base model, create one-shot example from the validation dataset, and generate simplified sentences for the test dataset. The results will be saved in a JSON file.

**Evaluating the Results**
To evaluate the generated results using SARI and BERTScore, run:
`python evaluate.py`

This script will load the generated JSON files and compute the SARI and BERTScore metrics, providing an aggregated evaluation of the model's performance.

**Acknowledgements** 
This work builds upon the pre-trained Flan-T5-base model and leverages the EASSE package for evaluation. We acknowledge the contributions of the authors and developers of these tools.

**License** 
This project is licensed under the MIT License. See the LICENSE file for details.
